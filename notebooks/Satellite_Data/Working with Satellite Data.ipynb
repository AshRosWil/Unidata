{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "<div style=\"width:1000 px\">\n",
    "\n",
    "<div style=\"float:right; width:98 px; height:98px;\"><img src=\"https://pbs.twimg.com/profile_images/1187259618/unidata_logo_rgb_sm_400x400.png\" alt=\"Unidata Logo\" style=\"height: 98px;\"></div>\n",
    "\n",
    "<h1>Working with Satellite Data</h1>\n",
    "<h3>Unidata Python Workshop</h3>\n",
    "\n",
    "<div style=\"clear:both\"></div>\n",
    "</div>\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "<div style=\"float:right; width:250 px\"><img src=\"https://unidata.github.io/MetPy/latest/_images/sphx_glr_GINI_Water_Vapor_001.png\" alt=\"Example Satellite Image\" style=\"height: 500px;\"></div>\n",
    "\n",
    "\n",
    "## Overview:\n",
    "\n",
    "* **Teaching:** 60 minutes\n",
    "* **Exercises:** 30 minutes\n",
    "\n",
    "### Questions\n",
    "1. How can satellite data be obtained with Siphon?\n",
    "1. What format is satellite data distributed in?\n",
    "1. How can MetPy be used to open and explore satellite data?\n",
    "1. How can maps of satellite data be made?\n",
    "1. How can other datasets be integrated with satellite data?\n",
    "\n",
    "### Objectives\n",
    "1. <a href=\"#downloaddata\">Download satellite data with Siphon</a>\n",
    "1. <a href=\"#parsenetcdf\">Parse out netCDF file</a>\n",
    "1. <a href=\"#plot\">Make a plot of the data</a>\n",
    "1. <a href=\"#colortables\">Use colortables and annotations</a>\n",
    "1. <a href=\"#animation\">Bonus: Animations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"downloaddata\"></a>\n",
    "## 1. Download satellite data with Siphon\n",
    "\n",
    "The first step is to find the satellite data. Normally, we would browse over to http://thredds.ucar.edu/thredds/ and find the top-level [THREDDS Data Server (TDS)](https://www.unidata.ucar.edu/software/thredds/current/tds/TDS.html) catalog. From there we can drill down to find satellite data products.\n",
    "\n",
    "For this tutorial, we want to utilize the new GOES-16 imagery. This imagery is still considered experimental and not for operational use, so it is found on the test dataserver at http://thredds-test.unidata.ucar.edu/. For current data, you could navigate to the `Test Datasets` directory, then `GOES-16 Products` and `GOES-16`. There are subfolders for the CONUS, full disk, and mesoscale sector images. In each of theses is a folder for each [channel of the ABI](http://www.goes-r.gov/education/ABI-bands-quick-info.html). In each channel there is a folder for every day in the month-long rolling archive. As you can see, there is a massive amount of data coming down from GOES-16! For the workshop we will be using archived case study data from Irma located at [http://thredds-test.unidata.ucar.edu/thredds/catalog/casestudies/irma/goes16](http://thredds-test.unidata.ucar.edu/thredds/catalog/casestudies/irma/goes16).\n",
    "\n",
    "We could download the files to our computers from here, but that can become tedious for downloading many files, requires us to store them on our computer, and does not lend itself to automation.\n",
    "\n",
    "We can use Unidata's [Siphon](https://github.com/Unidata/siphon) package to parse the catalog from the TDS. This provides us a nice programmatic way of accessing the data. We start by importing the `TDSCatalog` class from siphon and giving it the URL to the catalog we just surfed to manually. **Note:** Instead of giving it the link to the HTML catalog, we change the extension to XML, which asks the TDS for the XML version of the catalog. This is much better to work with in code. \n",
    "\n",
    "Next we'll build a URL to get to the current data for a specified channel and region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from siphon.catalog import TDSCatalog\n",
    "\n",
    "date = datetime.utcnow()\n",
    "channel = 8\n",
    "region = 'Mesoscale-2'\n",
    "\n",
    "cat = TDSCatalog('http://thredds-test.unidata.ucar.edu/thredds/catalog/satellite/goes16/GOES16/'\n",
    "                 '{}/Channel{:02d}/{:%Y%m%d}/catalog.xml'.format(region, channel, date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a `TDSCatalog` object called `cat` that we can examine and use to get handles to work with the data. To find the latest file, we can look at the `cat.datasets` attribute. This is a Python dictionary, mapping the name of the dataset to a Python Dataset object (which came from more XML supplied by the TDS). Since this is a dictionary, we can look at a list of keys and see what datasets are available. Letâ€™s look at the last five keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.datasets[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get the next to most recent dataset (sometimes the most recent will not have received all tiles yet) using the OPENDAP protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cat.datasets[-2]\n",
    "ds = ds.remote_access(service='OPENDAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use xarray to open the dataset as a netCDF data store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metpy\n",
    "import xarray as xr\n",
    "from xarray.backends import NetCDF4DataStore\n",
    "ds = NetCDF4DataStore(ds)\n",
    "ds = xr.open_dataset(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>Using the link to the Hurricane Irma archive above, get data from September 10, 2017 at 15Z for the mid-level water vapor channel (9) in the Mesoscale-1 sector. You could search through the datasets list manually, but instead try the `cat.datasets.filter_time_nearest` functionality!</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol1\" class='btn btn-primary'>View Solution</button>\n",
    "<div id=\"sol1\" class=\"collapse\">\n",
    "<code><pre>\n",
    "cat = TDSCatalog('http://thredds-test.unidata.ucar.edu/thredds/catalog/casestudies/irma/goes16/Mesoscale-1/Channel09/20170910/catalog.xml')\n",
    "ds = cat.datasets.filter_time_nearest(datetime(2017, 9, 10, 0))\n",
    "print(ds.name)\n",
    "ds = ds.remote_access(service='OPENDAP')\n",
    "ds = NetCDF4DataStore(ds)\n",
    "ds = xr.open_dataset(ds)\n",
    "</pre></code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Top</a>\n",
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"parsenetcdf\"></a>\n",
    "## 2. Parse out the netCDF File\n",
    "\n",
    "We have a [netCDF4-python](https://unidata.github.io/netcdf4-python/) dataset object now that contains all of the data for a given satellite image. We need to explore the variables available in the file and pull out the useful parts that we need to make a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to plot the imagery, so we'll be using the `Sectorized_CMI` variable from the `.variables` dictionary.\n",
    "Rather than just giving back the raw array of data, this gives back a `Variable` object; from here not only\n",
    "can we get the raw data values, but there are useful metadata as well. We can see just what additional information\n",
    "is present by printing out the `Variable` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_var = ds['Sectorized_CMI']\n",
    "print(data_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals several useful pieces of information (such as a longer description of the variable), but we're going to focus on the `grid_mapping` data. This attribute is defined by the [NetCDF Climate and Forecast (CF) Metadata Conventions](http://cfconventions.org/cf-conventions/v1.6.0/cf-conventions.html) and specifies a variable that contains information about the grid's projection.\n",
    "\n",
    "We also need to get the x and y coordinates of the image from the dataset object. We use an empty slice (`[:]`) to copy the actual numeric values out of the variables (for easier use with matplotlib and cartopy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds['x']\n",
    "y = ds['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection is generally [Lambert conformal conic](https://en.wikipedia.org/wiki/Lambert_conformal_conic_projection) or [Mercator](https://en.wikipedia.org/wiki/Mercator_projection) depending on the sector. The meta-data includes a few parameters (such as the latitude and longitude of the origin) needed to properly set up the projection to match what was used to create the image. There is also has information about the assumed shape of the earth, which in this case is spherical with a radius of 6371.2 km. We can let MetPy parse the information and build a projection for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = ds.metpy.parse_cf('Sectorized_CMI')\n",
    "proj = dat.metpy.cartopy_crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Top</a>\n",
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"plot\"></a>\n",
    "## 3. Make a plot of the data\n",
    "\n",
    "We are finally ready to plot the satellite data! Using `imshow()` we can get an image, but there is a lot of work to do here. The data need to be projected to a meaningful representation, map outlines added, and annotations added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the notebook puts figures inline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to properly reference the imagery data, we can plot\n",
    "the data. CartoPy's projections are designed to interface with matplotlib, so they can just be passed as the `projection` keyword argument when creating an `Axes` using the `add_subplot` method. Since the x and y coordinates, as well as the image data, are referenced in the lambert conformal projection, we can pass all of them directly to plotting methods (such as `imshow`) with no additional information. The `extent` keyword argument to `imshow` is used to specify the bounds of the image data being plotted. It is **especially important** to specify that the `origin` is at the upper left of the image (standard practice in imagery). If your forget this, your image will be flipped. Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure with size 10\" by 10\"\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Put a single axes on this figure; set the projection for the axes to be our\n",
    "# Lambert conformal projection\n",
    "ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "\n",
    "# Plot the data with mostly the defaults\n",
    "# Note, we save the image returned by imshow for later...\n",
    "im = ax.imshow(data_var[:], extent=(x.min(), x.max(), y.min(), y.max()), origin='upper')\n",
    "\n",
    "# Add high-resolution coastlines to the plot\n",
    "ax.coastlines(resolution='50m', color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nice start, but it would be nice to have better geographic references for the image. For example, where are the states? Cartopy's `feature` module has support for adding geographic features to plots, with many features are built in. The `BORDERS` built-in feature contains country borders and `STATES` contains US state boundaries. There is also support for creating \"custom\" features from the [Natural Earth](http://www.naturalearthdata.com/) set of free vector and raster map data (CartoPy will automatically download the necessary data and cache it locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Add country borders with a thick line.\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=2, edgecolor='black')\n",
    "\n",
    "# Add state borders with dotted lines, denoted by ':'\n",
    "ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='black')\n",
    "\n",
    "# Redisplay modified figure\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Top</a>\n",
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"colortables\"></a>\n",
    "## 4. Use colortables and annotations\n",
    "\n",
    "The map is much improved now, but it would look much better with a different color scheme. \n",
    "\n",
    "Colormapping in matplotlib (which backs CartoPy) is handled through two pieces:\n",
    "\n",
    "- The colormap controls how values are converted from floating point values in the range [0, 1] to colors (think colortable)\n",
    "- The norm (normalization) controls how data values are converted to floating point values in the range [0, 1]\n",
    "\n",
    "Let's start by setting the colormap to be black and white and normalizing the data to get the best contrast. We'll make a histogram to see the distribution of values in the data, then clip that range down to enhance contrast in the data visualization.  **Note:** `cmap` and `norm` can also be set during the `imshow` call as keyword arguments.\n",
    "\n",
    "We `flatten` the 2D array down to 1D for the histogram and remove any masked elements with `compressed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_var.to_masked_array().compressed().flatten(), bins=255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set colormap\n",
    "im.set_cmap('Greys')\n",
    "\n",
    "# Set norm\n",
    "im.set_norm(plt.Normalize(200,255))\n",
    "\n",
    "# Show figure again\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In meteorology, we have many â€˜standardâ€™ colortables that have been used for certain types of data. We have included these in Metpy in the `metpy.plots.ctables` module. By importing the `ColortableRegistry` we gain access to the colortables, as well as handy normalizations to go with them. We can see the colortables available by looking at the dictionary keys. The colortables ending in `_r` are the reversed versions of the named colortable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metpy.plots import colortables\n",
    "\n",
    "[table for table in colortables.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s use the `WVCIMSS` colormap, a direct conversion of the GEMPAK colormap. The code below asks for the colormap, as well as a normalization that covers the range 195 to 265. This was empirically determined to closely match other displays of water vapor data. We then apply it to the existing image we have been working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_norm, wv_cmap = colortables.get_with_range('WVCIMSS_r', 195, 265)\n",
    "im.set_cmap(wv_cmap)\n",
    "im.set_norm(wv_norm)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing that would be nice is putting the date and time on the image, so let's do that. First grab the `start_date_time` attribute from the dataset object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.start_date_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This timestamp contains the year, Julian day, hour, minute, and second that the image was collected. We will use `datetime.strptime` to parse this out into a Python `datetime` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.strptime(ds.start_date_time, '%Y%j%H%M%S')\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Python `datetime` object is easy to work with. Let's add it to our plot.\n",
    "\n",
    "We use the `text` method to draw text on our plot. In this case, we call it with a `transform` keyword argument, which allows us to tell matplotlib how to interpret the x and y coordinates. In this case, we set the transform to `ax.transAxes`, which means \"interpret x and y as being in axes space\". The axes space has x and y in the range [0, 1] across the entire plotting area (e.g. (0, 0) is lower left, (1, 1) is upper right). Using this, we can put text in the lower right corner (`x = 0.99`, `y = 0.01`) regardless of the range of x and y (or longitude and latitude) in the plot. We also need to make sure to right-align the text so that the text *ends* at the specified point.\n",
    "\n",
    "We use the `strftime` method to format the datetime as a string. The details of that format string are described [here](https://docs.python.org/3.5/library/datetime.html#strftime-strptime-behavior).\n",
    "\n",
    "We also need to add an annotation telling us what channel is being plotted, as well as a statement that the data are experimental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text (aligned to the right); save the returned object so we can manipulate it.\n",
    "text_time = ax.text(0.99, 0.01, timestamp.strftime('%d %B %Y %H%MZ'),\n",
    "               horizontalalignment='right', transform=ax.transAxes,\n",
    "               color='white', fontsize='x-large', weight='bold')\n",
    "\n",
    "text_channel = ax.text(0.5, 0.97, 'GOES-16 Ch.{}'.format(channel),\n",
    "               horizontalalignment='center', transform=ax.transAxes,\n",
    "               color='white', fontsize='large', weight='bold')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's a good idea, but the text is invisible in some places! White text and black text have issues, but we can outline the text using matplotlib's [path effects](http://matplotlib.org/users/patheffects_guide.html). More details on path effects can be found in the [documentation](http://matplotlib.org/users/patheffects_guide.html) if you want to know more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the text stand out even better using matplotlib's path effects\n",
    "from matplotlib import patheffects\n",
    "outline_effect = [patheffects.withStroke(linewidth=2, foreground='black')]\n",
    "text_time.set_path_effects(outline_effect)\n",
    "text_channel.set_path_effects(outline_effect)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the MetPy or Unidata Logo\n",
    "from metpy.plots import add_metpy_logo, add_unidata_logo\n",
    "add_metpy_logo(fig)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>In one cell write all necessary code to make a plot of the CONUS sector using a channel of your choice. You may plot data from any time on September 9, 2017. (Re-writing the import statements is not necessary.)</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#sol2\" class='btn btn-primary'>View Solution</button>\n",
    "<div id=\"sol2\" class=\"collapse\">\n",
    "<code><pre>\n",
    "cat = TDSCatalog('http://thredds-test.unidata.ucar.edu/thredds/catalog/casestudies/irma/goes16/CONUS/Channel10/20170909/catalog.xml')\n",
    "ds = cat.datasets.filter_time_nearest(datetime(2017, 9, 9, 6))\n",
    "print(ds.name)\n",
    "ds = ds.remote_access(service='OPENDAP')\n",
    "ds = NetCDF4DataStore(ds)\n",
    "ds = xr.open_dataset(ds)\n",
    "timestamp = datetime.strptime(ds.start_date_time, '%Y%j%H%M%S')\n",
    "data_var = ds.metpy.parse_cf('Sectorized_CMI')\n",
    "\n",
    "x = ds['x']\n",
    "y = ds['y']\n",
    "\n",
    "wv_norm, wv_cmap = colortables.get_with_range('WVCIMSS_r', 195, 265)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=data_var.metpy.cartopy_crs)\n",
    "\n",
    "im = ax.imshow(data_var[:], extent=(x.min(), x.max(), y.min(), y.max()), origin='upper',\n",
    "               cmap=wv_cmap, norm=wv_norm)\n",
    "ax.coastlines(resolution='50m', color='black')\n",
    "ax.add_feature(cfeature.STATES, linestyle=':')\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=2)\n",
    "\n",
    "# Add text (aligned to the right); save the returned object so we can manipulate it.\n",
    "text_time = ax.text(0.99, 0.01, timestamp.strftime('%d %B %Y %H%MZ'),\n",
    "               horizontalalignment='right', transform=ax.transAxes,\n",
    "               color='white', fontsize='x-large', weight='bold')\n",
    "\n",
    "text_channel = ax.text(0.5, 0.97, 'Experimental GOES-16 Ch.{}'.format(channel),\n",
    "               horizontalalignment='center', transform=ax.transAxes,\n",
    "               color='white', fontsize='large', weight='bold')\n",
    "\n",
    "outline_effect = [patheffects.withStroke(linewidth=2, foreground='black')]\n",
    "text_time.set_path_effects(outline_effect)\n",
    "text_channel.set_path_effects(outline_effect)\n",
    "\n",
    "fig = add_metpy_logo(fig)\n",
    "</pre></code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Top</a>\n",
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"animation\"></a>\n",
    "## Bonus: Animations\n",
    "**NOTE:**\n",
    "This is just a quick taste of producing an animation using matplotlib. The animation support in matplotlib is robust, but sometimes installation of the underlying tools (mencoder/ffmpeg) can be a little tricky. In order to make sure we get don't get bogged down, this is really more of a demo than something expected to work out of the box.\n",
    "\n",
    "For windows builds, you might try:\n",
    "- For [ffmpeg](https://ffmpeg.zeranoe.com/builds/)\n",
    "- For [mencoder](https://www.mplayerhq.hu/design7/dload.html)\n",
    "\n",
    "On OSX and linux, conda-forge has packages, so it may be as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y -n unidata-workshop -c http://conda.anaconda.org/conda-forge ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the animation support from matplotlib. We also tell it that we want it to render the animations to HTML using the HTML5 video tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import ArtistAnimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the base figure, then we loop over a bunch of the datasets to create an animation. For each one we pull out the data and plot both the timestamp and the image. The `ArtistAnimation` class takes the `Figure` instance and a list as required arguments. The contents of this list are a collection of matplotlib artists for each frame of the animation. In the loop below, we populate this list with the `Text` instance created when adding the timestamp as well as the image that results from plotting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['animation.embed_limit'] = 50\n",
    "\n",
    "# List used to store the contents of all frames. Each item in the list is a tuple of\n",
    "# (image, text)\n",
    "artists = []\n",
    "\n",
    "# Get the IRMA case study catalog\n",
    "cat = TDSCatalog('http://thredds-test.unidata.ucar.edu/thredds/catalog/casestudies/irma'\n",
    "                 '/goes16/Mesoscale-1/Channel{:02d}/{:%Y%m%d}/'\n",
    "                 'catalog.xml'.format(channel, datetime(2017, 9, 9)))\n",
    "    \n",
    "datasets = cat.datasets.filter_time_range(datetime(2017, 9, 9), datetime(2017, 9, 9, 6))\n",
    "\n",
    "# Grab the first dataset and make the figure using its projection information\n",
    "ds = datasets[0]\n",
    "ds = ds.remote_access(service='OPENDAP')\n",
    "ds = NetCDF4DataStore(ds)\n",
    "ds = xr.open_dataset(ds)\n",
    "dat = ds.metpy.parse_cf('Sectorized_CMI')\n",
    "proj = dat.metpy.cartopy_crs\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "plt.subplots_adjust(left=0.005, bottom=0.005, right=0.995, top=0.995, wspace=0, hspace=0)\n",
    "ax.coastlines(resolution='50m', color='black')\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=2)\n",
    "\n",
    "# Add the MetPy Logo\n",
    "add_metpy_logo(fig, x=15, y=15)\n",
    "\n",
    "# Loop over the datasets and make the animation\n",
    "for ds in datasets[::6]:\n",
    "\n",
    "    # Open the data\n",
    "    ds = ds.remote_access(service='OPENDAP')\n",
    "    ds = NetCDF4DataStore(ds)\n",
    "    ds = xr.open_dataset(ds)\n",
    "    \n",
    "    # Pull out the image data, x and y coordinates, and the time. Also go ahead and\n",
    "    # convert the time to a python datetime\n",
    "    x = ds['x']\n",
    "    y = ds['y']\n",
    "    timestamp = datetime.strptime(ds.start_date_time, '%Y%j%H%M%S')\n",
    "    img_data = ds['Sectorized_CMI']\n",
    "\n",
    "    # Plot the image and the timestamp. We save the results of these plotting functions\n",
    "    # so that we can tell the animation that these two things should be drawn as one\n",
    "    # frame in the animation\n",
    "    im = ax.imshow(img_data, extent=(x.min(), x.max(), y.min(), y.max()), origin='upper',\n",
    "                   cmap=wv_cmap, norm=wv_norm)\n",
    "\n",
    "    # Add text (aligned to the right); save the returned object so we can manipulate it.\n",
    "    text_time = ax.text(0.99, 0.01, timestamp.strftime('%d %B %Y %H%MZ'),\n",
    "                   horizontalalignment='right', transform=ax.transAxes,\n",
    "                   color='white', fontsize='x-large', weight='bold', animated=True)\n",
    "\n",
    "    text_channel = ax.text(0.5, 0.97, 'Experimental GOES-16 Ch.{}'.format(channel),\n",
    "                   horizontalalignment='center', transform=ax.transAxes,\n",
    "                   color='white', fontsize='large', weight='bold', animated=True)\n",
    "\n",
    "    # Make the text stand out even better using matplotlib's path effects\n",
    "    outline_effect = [patheffects.withStroke(linewidth=2, foreground='black')]\n",
    "    text_time.set_path_effects(outline_effect)\n",
    "    text_channel.set_path_effects(outline_effect)\n",
    "    \n",
    "    # Stuff them in a tuple and add to the list of things to animate\n",
    "    artists.append((im, text_time, text_channel))\n",
    "\n",
    "# Create the animation--in addition to the required args, we also state that each\n",
    "# frame should last 200 milliseconds\n",
    "anim = ArtistAnimation(fig, artists, interval=200., blit=False)\n",
    "anim.save('GOES_Animation.mp4')\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Top</a>\n",
    "<hr style=\"height:2px;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
